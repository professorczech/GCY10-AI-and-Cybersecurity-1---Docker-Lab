
<style>
.codewrap{margin:12px 0 18px 0;}
.copybtn{padding:8px 12px;border:1px solid #444;border-radius:8px;background:#111;color:#fff;cursor:pointer;}
.copybtn:hover{background:#1a1a1a;}
.copyhint{margin:8px 0 8px 0;font-size:0.9em;opacity:0.85;}
.codebox{width:100%;min-height:420px;white-space:pre;font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  font-size:12px;line-height:1.35;padding:12px;border-radius:10px;border:1px solid #333;background:#0b0b0b;color:#eaeaea;}
</style>
<div style="font-family: 'Segoe UI', Helvetica, Arial, sans-serif; max-width: 900px; margin: 0 auto; line-height: 1.6; color: #333;">

    <h1 style="border-bottom: 2px solid #d12424; padding-bottom: 10px; color: #d12424;">Lab Exercise: ML Phishing Analysis</h1>
    
    <p><strong>Welcome to the SOC.</strong> Today, we aren't just reading about AI security; we are building an automated pipeline to detect it. You will link your <strong>SOC Desktop</strong> (where the victim lives) to <strong>Shuffle SOAR</strong> (where the automation lives) to analyze a phishing attack in real-time.</p>

    <div style="background-color: #eef6fc; padding: 15px; border-left: 5px solid #0056b3; margin-bottom: 25px;">
        <strong>Lab Objective:</strong><br>
        Simulate an "Automated Forwarding Rule" that sends suspicious emails from the desktop to a Machine Learning workflow for analysis.
    </div>

    <hr style="border: 0; border-top: 1px solid #eee; margin: 30px 0;">

    <h2 style="color: #0056b3;">Part 0: Pre-Flight Checks & Troubleshooting</h2>
    <p>Before you start, verify your environment is active. If the execution fails with "Client version too old", run the fix below.</p>
    <ul>
        <li><strong>Desktop:</strong> <a href="http://localhost:6080" target="_blank">http://localhost:6080</a> (Should see Ubuntu)</li>
        <li><strong>Shuffle:</strong> <a href="http://localhost:3001" target="_blank">http://localhost:3001</a> (Should see Login)</li>
    </ul>

    <div style="background-color: #fff3cd; color: #856404; padding: 15px; border: 1px solid #ffeeba; border-radius: 5px; margin-top: 10px;">
        <strong>⚠️ Critical Fix: If your Workflow stays "Grey" or won't run:</strong><br>
        Open a terminal in your Shuffle directory and run these commands to update the Docker execution engine:<br>
        <code style="display:block; background:#333; color:#fff; padding:5px; margin-top:5px;">docker compose down<br>docker compose pull<br>docker compose up -d</code>
    </div>

    <hr style="border: 0; border-top: 1px solid #eee; margin: 30px 0;">

    <h2 style="color: #0056b3;">Part 1: Build the Brain (Shuffle Workflow)</h2>
    
    <h3>1.1 Create the Webhook Trigger</h3>
    <ol>
        <li>Log into <strong>Shuffle</strong>.</li>
        <li>Create a <strong>New Workflow</strong> named "ML Phishing Analyzer".</li>
        <li>Drag the <strong>Webhook</strong> trigger onto the canvas from the left sidebar.</li>
        <li><strong>CRITICAL STEP:</strong> Click the Webhook node to select it, then copy the <strong>Webhook URI</strong> displayed in the settings.
            <br><em>It looks like: <code>http://localhost:3001/api/v1/hooks/webhook_...</code></em>
        </li>
        <li>Click the big <strong>Start</strong> button on the Webhook node.</li>
    </ol>

    <h3>1.2 Add the Feature Extractor</h3>
    <p>This node parses the raw email and calculates "Entropy" (randomness) to find weird links.</p>
    <ol>
        <li>Search for <strong>"Shuffle Tools"</strong> on the left sidebar and drag it onto the canvas.</li>
        <li><strong>CONNECT THE DOTS:</strong> Drag the small arrow from the <strong>Webhook</strong> node to this new node.</li>
        <li>Edit the node settings:
            <ul>
                <li><strong>Name:</strong> Feature_Extractor</li>
                <li><strong>Action:</strong> Execute Python</li>
                <li><strong>Code:</strong> Delete the default code and paste the code below.</li>
            </ul>
    <p><strong>Input wiring (no picker required):</strong> In the Feature Extractor node, set the <em>Execution argument</em> field to <code>{{ $exec }}</code> (type/paste it). This passes the webhook payload into the script.</p>

        </li>
    </ol>

    <details open>
        <summary style="cursor: pointer; font-weight: bold; color: #d12424;">Click to copy Python Code #1 (Feature_Extractor)</summary>
        <div class="codewrap">
  <button class="copybtn" type="button" onclick="copyCode('code_feature_extractor')">Copy to clipboard</button>
  <div class="copyhint">Or click inside, Ctrl+A, Ctrl+C.</div>
  <textarea id="code_feature_extractor" class="codebox" spellcheck="false" readonly>import base64
import json
import re
import ipaddress
import shutil
import subprocess
from email import policy
from email.parser import BytesParser
from email.utils import getaddresses
from math import log2
from urllib.parse import urlsplit

# ------------------------------------------------------------
# INPUT (Shuffle-safe): Inject ONLY the base64 string
# Use the + button and insert: $exec.data.eml_b64
# ------------------------------------------------------------
EML_B64 = r'''{{ $exec.data.eml_b64 }}'''

# Optional: If you ever switch to plain text injection later
EML_TEXT = r'''{{ $exec.data.eml_text }}'''

# Toggle DNS lookups (TXT records for SPF / DKIM key presence)
ENABLE_DNS_LOOKUPS = False

SUSPICIOUS_TLDS = set([
    "zip", "mov", "top", "xyz", "loan", "click", "support", "icu", "shop", "live", "fit"
])

URL_SHORTENERS = set([
    "bit.ly", "t.co", "tinyurl.com", "goo.gl", "ow.ly", "is.gd", "buff.ly", "cutt.ly"
])

PHISH_PHRASES = [
    "verify your account", "account suspended", "password reset", "confirm your password",
    "unusual activity", "urgent", "immediately", "last warning", "click here",
    "sign in", "invoice", "wire transfer", "payment failed", "security alert",
    "update your billing", "locked", "restricted", "validate", "authenticate"
]

SUSPICIOUS_ATTACHMENT_EXTS = set([
    "exe", "js", "vbs", "vbe", "scr", "bat", "cmd", "ps1", "hta",
    "iso", "img", "lnk", "zip", "rar", "7z", "html"
])

# ----------------------------
# Helpers
# ----------------------------

def shannon_entropy(s):
    if not s:
        return 0.0
    counts = {}
    for ch in s:
        counts[ch] = counts.get(ch, 0) + 1
    n = float(len(s))
    ent = 0.0
    for c in counts.values():
        p = c / n
        ent -= p * log2(p)
    return ent

def strip_html(s):
    s = re.sub(r"<script[\s\S]*?</script>", " ", s, flags=re.I)
    s = re.sub(r"<style[\s\S]*?</style>", " ", s, flags=re.I)
    s = re.sub(r"<[^>]+>", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def extract_body_parts(msg):
    plain_parts = []
    html_parts_stripped = []
    html_parts_raw = []

    if msg.is_multipart():
        for part in msg.walk():
            ctype = (part.get_content_type() or "").lower()
            if ctype not in ("text/plain", "text/html"):
                continue
            try:
                content = part.get_content()
                if not content:
                    continue
                if ctype == "text/plain":
                    plain_parts.append(content)
                else:
                    html_parts_raw.append(content)
                    html_parts_stripped.append(strip_html(content))
            except Exception:
                pass
    else:
        try:
            ctype = (msg.get_content_type() or "").lower()
            content = msg.get_content()
            if content:
                if ctype == "text/html":
                    html_parts_raw.append(content)
                    html_parts_stripped.append(strip_html(content))
                else:
                    plain_parts.append(content)
        except Exception:
            pass

    plain_text = "\n".join([p for p in plain_parts if p])
    html_text_stripped = "\n".join([p for p in html_parts_stripped if p])
    html_raw = "\n".join([p for p in html_parts_raw if p])
    return plain_text, html_text_stripped, html_raw

def get_first_address_domain(header_value):
    addrs = getaddresses([header_value or ""])
    if not addrs:
        return None, None
    _name, email_addr = addrs[0]
    email_addr = (email_addr or "").strip()
    if "@" in email_addr:
        domain = email_addr.split("@", 1)[1].lower()
        return email_addr, domain
    return (email_addr or None), None

def parse_auth_results(authres):
    out = {"spf": "unknown", "dkim": "unknown", "dmarc": "unknown"}
    if not authres:
        return out

    m_spf = re.search(r"\bspf\s*=\s*(pass|fail|softfail|neutral|none|temperror|permerror)\b", authres, flags=re.I)
    if m_spf:
        out["spf"] = m_spf.group(1).lower()

    m_dkim = re.search(r"\bdkim\s*=\s*(pass|fail|none|neutral|policy|temperror|permerror)\b", authres, flags=re.I)
    if m_dkim:
        out["dkim"] = m_dkim.group(1).lower()

    m_dmarc = re.search(r"\bdmarc\s*=\s*(pass|fail|bestguesspass|none)\b", authres, flags=re.I)
    if m_dmarc:
        out["dmarc"] = m_dmarc.group(1).lower()

    return out

def parse_received_spf(received_spf):
    if not received_spf:
        return "unknown"
    m = re.search(r"^(pass|fail|softfail|neutral|none|temperror|permerror)\b", received_spf.strip(), flags=re.I)
    return m.group(1).lower() if m else "unknown"

def looks_like_ip(host):
    try:
        ipaddress.ip_address(host)
        return True
    except Exception:
        return False

def extract_urls(text, html_raw):
    urls = set()

    if text:
        for u in re.findall(r"https?://[^\s\"'<>]+", text, flags=re.I):
            urls.add(u)

    if html_raw:
        for u in re.findall(r'href\s*=\s*["\'](https?://[^"\']+)["\']', html_raw, flags=re.I):
            urls.add(u)
        for u in re.findall(r'src\s*=\s*["\'](https?://[^"\']+)["\']', html_raw, flags=re.I):
            urls.add(u)

    cleaned = []
    for u in sorted(urls):
        u2 = u.split("#", 1)[0].strip()
        cleaned.append(u2)
    return cleaned

def dns_txt_lookup(name):
    # dnspython if present
    try:
        import dns.resolver  # type: ignore
        answers = dns.resolver.resolve(name, "TXT")
        out = []
        for r in answers:
            chunks = []
            for s in getattr(r, "strings", []):
                try:
                    chunks.append(s.decode("utf-8", "replace"))
                except Exception:
                    chunks.append(str(s))
            if chunks:
                out.append("".join(chunks))
            else:
                out.append(str(r))
        return out
    except Exception:
        pass

    # dig
    if shutil.which("dig"):
        try:
            p = subprocess.run(["dig", "+short", "TXT", name], capture_output=True, text=True, timeout=2)
            lines = [ln.strip().strip('"') for ln in (p.stdout or "").splitlines() if ln.strip()]
            return lines or None
        except Exception:
            return None

    # nslookup
    if shutil.which("nslookup"):
        try:
            p = subprocess.run(["nslookup", "-type=TXT", name], capture_output=True, text=True, timeout=2)
            out = []
            for ln in (p.stdout or "").splitlines():
                if "text =" in ln.lower():
                    out.append(ln.split("=", 1)[-1].strip().strip('"'))
            return out or None
        except Exception:
            return None

    return None

def get_spf_record(domain):
    txts = dns_txt_lookup(domain) or []
    for t in txts:
        if "v=spf1" in t.lower():
            return t
    return None

def get_dkim_key(selector, dkim_domain):
    name = (selector + "._domainkey." + dkim_domain).strip(".")
    txts = dns_txt_lookup(name) or []
    return txts[0] if txts else None

# ----------------------------
# Main
# ----------------------------

b64 = (EML_B64 or "").strip()
eml_text = (EML_TEXT or "").strip()

if (not b64 or b64 == "null") and (not eml_text or eml_text == "null"):
    print(json.dumps({
        "success": False,
        "error": "No email content injected. Expected $" + "exec.data.eml_b64 (preferred) or $" + "exec.data.eml_text."
    }))
    raise SystemExit(0)

eml_bytes = b""
if b64 and b64 != "null":
    try:
        eml_bytes = base64.b64decode(b64)
    except Exception as e:
        print(json.dumps({"success": False, "error": "Base64 decode failed: {0}".format(e)}))
        raise SystemExit(0)
else:
    eml_bytes = eml_text.encode("utf-8", errors="replace")

msg = BytesParser(policy=policy.default).parsebytes(eml_bytes)

# Basic headers
subject = msg.get("subject", "") or ""
from_h = msg.get("from", "") or ""
reply_to = msg.get("reply-to", "") or ""
return_path = msg.get("return-path", "") or ""
message_id = msg.get("message-id", "") or ""
date_h = msg.get("date", "") or ""

from_addr, from_domain = get_first_address_domain(from_h)
reply_addr, reply_domain = get_first_address_domain(reply_to)
rp_addr, rp_domain = get_first_address_domain(return_path)

reply_to_mismatch = bool(reply_domain and from_domain and (reply_domain != from_domain))
return_path_mismatch = bool(rp_domain and from_domain and (rp_domain != from_domain))

# Auth parsing
authres = msg.get("Authentication-Results", "") or ""
recv_spf = msg.get("Received-SPF", "") or ""
auth_parsed = parse_auth_results(authres)

spf_result = auth_parsed.get("spf", "unknown")
if spf_result == "unknown":
    spf_result = parse_received_spf(recv_spf)

dkim_result = auth_parsed.get("dkim", "unknown")
dmarc_result = auth_parsed.get("dmarc", "unknown")

# DKIM selector/domain (for optional DNS)
dkim_sig = msg.get("DKIM-Signature", "") or ""
dkim_selector = None
dkim_domain = None
if dkim_sig:
    m_s = re.search(r"\bs\s*=\s*([^; \t]+)", dkim_sig)
    m_d = re.search(r"\bd\s*=\s*([^; \t]+)", dkim_sig)
    if m_s:
        dkim_selector = m_s.group(1).strip()
    if m_d:
        dkim_domain = m_d.group(1).strip().lower()

# Body extraction
plain_text, html_text_stripped, html_raw = extract_body_parts(msg)
full_text = "\n".join([t for t in [plain_text, html_text_stripped] if t]).strip()
full_text_l = (full_text or "").lower()

has_html = bool(html_raw.strip())
has_form = bool(re.search(r"<form\b", html_raw, flags=re.I)) if html_raw else False
has_password_field = bool(re.search(r'type\s*=\s*["\']password["\']', html_raw, flags=re.I)) if html_raw else False

# Attachments
attachments = []
has_suspicious_attachment = False

if msg.is_multipart():
    for part in msg.walk():
        disp = (part.get("Content-Disposition", "") or "").lower()
        filename = part.get_filename()
        if not filename and "attachment" not in disp:
            continue
        filename = filename or ""
        ext = filename.rsplit(".", 1)[-1].lower() if "." in filename else ""
        ctype = (part.get_content_type() or "").lower()
        attachments.append({"filename": filename, "ext": ext, "content_type": ctype})
        if ext in SUSPICIOUS_ATTACHMENT_EXTS:
            has_suspicious_attachment = True

# URL features
urls = extract_urls(full_text, html_raw)
domains = []
url_features = []
pathq_entropies = []

suspicious_flags = {
    "any_ip_host": False,
    "any_punycode": False,
    "any_shortener": False,
    "any_suspicious_tld": False,
    "any_non_ascii_domain": False,
    "any_at_in_url": False
}

for u in urls:
    clean = u.split("#", 1)[0]
    parts = urlsplit(clean)
    host = (parts.hostname or "").strip().lower()
    domain = host
    tld = domain.rsplit(".", 1)[-1] if "." in domain else ""

    path_q = (parts.path or "") + ("?" + parts.query if parts.query else "")
    e_pq = shannon_entropy(path_q)
    pathq_entropies.append(e_pq)

    if looks_like_ip(domain):
        suspicious_flags["any_ip_host"] = True
    if domain.startswith("xn--") or ".xn--" in domain:
        suspicious_flags["any_punycode"] = True
    if domain in URL_SHORTENERS:
        suspicious_flags["any_shortener"] = True
    if tld in SUSPICIOUS_TLDS:
        suspicious_flags["any_suspicious_tld"] = True
    if any(ord(ch) > 127 for ch in domain):
        suspicious_flags["any_non_ascii_domain"] = True
    if "@" in clean:
        suspicious_flags["any_at_in_url"] = True

    domains.append(domain)

    url_features.append({
        "url": clean,
        "domain": domain,
        "tld": tld,
        "has_query": bool(parts.query),
        "entropy_url": round(shannon_entropy(clean), 4),
        "entropy_domain": round(shannon_entropy(domain), 4),
        "entropy_path_query": round(e_pq, 4)
    })

unique_domains = sorted(set([d for d in domains if d]))
unique_domain_count = len(unique_domains)

if not pathq_entropies:
    pathq_entropies = [0.0]

url_entropy_mean = sum(pathq_entropies) / float(len(pathq_entropies))
url_entropy_max = max(pathq_entropies)

# Phrase hits
phrase_hits = []
for p in PHISH_PHRASES:
    if p in full_text_l:
        phrase_hits.append(p)

# Simple style features
subject_len = len(subject)
subject_exclaim_count = subject.count("!")
body_exclaim_count = full_text.count("!")
digit_ratio = 0.0
if full_text:
    digit_ratio = float(sum(1 for c in full_text if c.isdigit())) / float(len(full_text))

upper_ratio = 0.0
letters = [c for c in subject if c.isalpha()]
if letters:
    upper_ratio = float(sum(1 for c in letters if c.isupper())) / float(len(letters))

# Optional DNS checks
dns_info = {
    "dns_attempted": False,
    "spf_record_found": False,
    "dkim_key_found": False,
    "spf_record": None,
    "dkim_selector": dkim_selector,
    "dkim_domain": dkim_domain,
    "dkim_key_snippet": None
}

if ENABLE_DNS_LOOKUPS:
    candidate_domain = from_domain or dkim_domain
    if candidate_domain:
        dns_info["dns_attempted"] = True
        try:
            spf_record = get_spf_record(candidate_domain)
            if spf_record:
                dns_info["spf_record_found"] = True
                dns_info["spf_record"] = spf_record[:500]
        except Exception:
            pass

    if dkim_selector and dkim_domain:
        dns_info["dns_attempted"] = True
        try:
            dkim_key = get_dkim_key(dkim_selector, dkim_domain)
            if dkim_key:
                dns_info["dkim_key_found"] = True
                dns_info["dkim_key_snippet"] = dkim_key[:120]
        except Exception:
            pass

# Teaching-friendly “signals”
signals = []

if spf_result in ("fail", "softfail", "permerror"):
    signals.append("SPF result indicates trouble: {0}".format(spf_result))
if dkim_result in ("fail", "permerror", "temperror"):
    signals.append("DKIM result indicates trouble: {0}".format(dkim_result))
if dmarc_result == "fail":
    signals.append("DMARC failed (alignment/policy signal)")

if reply_to_mismatch:
    signals.append("Reply-To domain differs from From domain (common phish pattern)")
if return_path_mismatch:
    signals.append("Return-Path domain differs from From domain (delivery-path mismatch)")
if has_password_field or (has_form and has_html):
    signals.append("HTML contains a form/password field (credential-harvest indicator)")
if has_suspicious_attachment:
    signals.append("Suspicious attachment extension detected")

if suspicious_flags.get("any_shortener"):
    signals.append("URL shortener present (can hide destination)")
if suspicious_flags.get("any_punycode") or suspicious_flags.get("any_non_ascii_domain"):
    signals.append("Potential IDN/punycode domain present (lookalike risk)")
if suspicious_flags.get("any_ip_host"):
    signals.append("URL host is a raw IP address (uncommon for legit org mail)")
if url_entropy_max >= 4.0:
    signals.append("High URL path/query entropy (often obfuscation / tracking / phish)")
if phrase_hits:
    preview = ", ".join(phrase_hits[:6])
    if len(phrase_hits) > 6:
        preview = preview + "..."
    signals.append("Phishy language patterns detected: {0}".format(preview))

# ------------------------------------------------------------
# OUTPUT (backwards-compatible keys + advanced fields)
# ------------------------------------------------------------
out = {
    "success": True,

    # Keep the core keys your Scoring_Engine likely expects
    "subject": subject,
    "from": from_h,
    "spf_result": spf_result,
    "dkim_result": dkim_result,
    "dmarc_result": dmarc_result,
    "body_len": len(full_text or ""),
    "phrase_hits": phrase_hits,
    "phrase_hit_count": len(phrase_hits),
    "url_entropy_mean": round(url_entropy_mean, 4),
    "url_entropy_max": round(url_entropy_max, 4),
    "url_count": len(url_features),
    "url_features": url_features,

    # Extra explainable / advanced fields
    "headers": {
        "from_addr": from_addr,
        "from_domain": from_domain,
        "reply_to": reply_to,
        "reply_domain": reply_domain,
        "return_path": return_path,
        "return_path_domain": rp_domain,
        "reply_to_mismatch": reply_to_mismatch,
        "return_path_mismatch": return_path_mismatch,
        "message_id_present": bool((message_id or "").strip()),
        "date": date_h,
        "authentication_results": authres[:5000],
        "received_spf": recv_spf[:2000]
    },

    "content": {
        "has_html": has_html,
        "has_form": has_form,
        "has_password_field": has_password_field,
        "subject_len": subject_len,
        "subject_upper_ratio": round(upper_ratio, 4),
        "subject_exclaim_count": subject_exclaim_count,
        "body_exclaim_count": body_exclaim_count,
        "digit_ratio": round(digit_ratio, 4)
    },

    "urls_meta": {
        "unique_domain_count": unique_domain_count,
        "unique_domains": unique_domains[:50],
        "suspicious_flags": suspicious_flags
    },

    "attachments": {
        "count": len(attachments),
        "has_suspicious_attachment": has_suspicious_attachment,
        "items": attachments[:50]
    },

    "dns": dns_info,
    "signals": signals
}

# ------------------------------------------------------------
# Compatibility layer for Scoring_Engine.py
# Scoring Engine expects: auth, urls, content, headers, attachments, dns
# ------------------------------------------------------------

# Ensure headers contains subject (Scoring Engine reads headers.subject)
try:
    if "headers" not in out or not isinstance(out.get("headers"), dict):
        out["headers"] = {}
    out["headers"]["subject"] = subject
except Exception:
    pass

# Ensure content contains the fields Scoring Engine expects
try:
    if "content" not in out or not isinstance(out.get("content"), dict):
        out["content"] = {}
    out["content"]["phrase_hit_count"] = int(len(phrase_hits))
    out["content"]["reply_to_mismatch"] = bool(reply_to_mismatch)
    # has_form / has_password_field already exist, but enforce anyway
    out["content"]["has_form"] = bool(has_form)
    out["content"]["has_password_field"] = bool(has_password_field)
except Exception:
    pass

# Build auth block expected by Scoring Engine
out["auth"] = {
    "spf_result": spf_result,
    "dkim_result": dkim_result,
    "dmarc_result": dmarc_result
}

# Build urls block expected by Scoring Engine
# Note: your current script uses urls_meta; Scoring Engine expects urls.suspicious_flags
out["urls"] = {
    "url_entropy_max": round(float(url_entropy_max), 4),
    "url_entropy_mean": round(float(url_entropy_mean), 4),
    "url_count": int(len(url_features)),
    "suspicious_flags": suspicious_flags
}

print(json.dumps(out))
</textarea>
</div>
    </details>

    
    <h3>1.3 Add the Ollama Analyst (AI Verdict)</h3>
    <ul>
        <li>Add another <strong>Tools → Execute Python</strong> node.</li>
        <li><strong>Name:</strong> Ollama_Analyst</li>
        <li>Connect <strong>Feature Extractor → Ollama_Analyst</strong> (same as Scoring Engine).</li>
        <li>This node <em>does not</em> read the raw email. It reads the <strong>Feature Extractor JSON</strong> and asks your local Ollama model for a verdict.</li>
    </ul>

    <details>
        <summary style="cursor: pointer; font-weight: bold; color: #d12424;">Click to copy Python Code #3 (Ollama_Analyst)</summary>
        <div class="codewrap">
            <button class="copybtn" type="button" onclick="copyCode('code_ollama_analyst')">Copy to clipboard</button>
            <div class="copyhint">Or click inside, Ctrl+A, Ctrl+C.</div>
            <textarea id="code_ollama_analyst" class="codebox" spellcheck="false" readonly>import json
import urllib.request

# --- 1. CONFIGURATION ---
# We point to the container name "soc-ollama" because we are on the same "soc-net" network
OLLAMA_URL = "http://soc-ollama:11434/api/generate"
MODEL = "cogito:3b"  # Make sure you ran 'ollama pull llama3'

# --- 2. DATA INJECTION ---
# Grab the CLEAN output from the previous node
INPUT_JSON = r'''{{ $feature_extractor }}'''

# --- 3. CONSTRUCT PROMPT ---
# We ask the LLM to act as a Level 2 Analyst
prompt = f"""
You are a Senior SOC Analyst. Review the following extracted email features and provide a verdict.
Focus on:
- High URL entropy (indicates random/generated domains)
- IP addresses in URLs
- Mismatches between 'From' and 'Reply-To'
- Phishing keywords

DATA JSON:
{INPUT_JSON}

TASK:
Provide a JSON response with exactly these keys:
- "reasoning": A short 1-sentence explanation of why it is safe or malicious.
- "confidence": A score between 0-100.
- "verdict": "SAFE", "SUSPICIOUS", or "MALICIOUS".
"""

# --- 4. SEND TO OLLAMA ---
payload = {
    "model": MODEL,
    "prompt": prompt,
    "stream": False,
    "format": "json"  # Forces Ollama to reply in strict JSON
}

try:
    # We use urllib to avoid dependency issues with 'requests' in minimal containers
    req = urllib.request.Request(
        OLLAMA_URL, 
        data=json.dumps(payload).encode('utf-8'), 
        headers={'Content-Type': 'application/json'}
    )
    
    with urllib.request.urlopen(req) as response:
        result = json.loads(response.read().decode('utf-8'))
        
        # The LLM's text reply is inside the "response" key
        llm_text = result.get("response", "{}")
        
        # Parse the inner JSON from the LLM
        try:
            analysis = json.loads(llm_text)
        except:
            # Fallback if LLM didn't give perfect JSON
            analysis = {"raw_output": llm_text, "verdict": "UNKNOWN"}

    # --- 5. OUTPUT ---
    print(json.dumps({
        "success": True,
        "model_used": MODEL,
        "ai_analysis": analysis
    }))

except Exception as e:
    print(json.dumps({"success": False, "error": f"Ollama Connection Failed: {str(e)}"}))</textarea>
        </div>
    </details>

    <p><strong>Note:</strong> If your Ollama container name or model differs, update <code>OLLAMA_URL</code> and <code>MODEL</code> at the top of the script.</p>

    <h3>1.4 Add the Scoring Engine</h3>
    <p>This node acts as the "AI Decision Maker", applying rules to the extracted features.</p>
    <ol>
        <li>Drag <strong>another</strong> "Shuffle Tools" node onto the canvas.</li>
        <li><strong>CONNECT:</strong> Drag the arrow from <strong>Feature_Extractor</strong> to this new node.</li>
        <li>Edit the node settings:
            <ul>
                <li><strong>Name:</strong> Scoring_Engine</li>
                <li><strong>Action:</strong> Execute Python</li>
                <li><strong>Code:</strong> Paste the code below.</li>
            </ul>
        </li>
    </ol>

    <details open>
        <summary style="cursor: pointer; font-weight: bold; color: #d12424;">Click to copy Python Code #2 (Scoring_Engine)</summary>
        <div class="codewrap">
  <button class="copybtn" type="button" onclick="copyCode('code_scoring_engine')">Copy to clipboard</button>
  <div class="copyhint">Or click inside, Ctrl+A, Ctrl+C.</div>
  <textarea id="code_scoring_engine" class="codebox" spellcheck="false" readonly>import json
import re

# ------------------------------------------------------------
# Scalar pulls from Feature Extractor output (NO raw email)
# Keep the same style as Scoring_Engine.bk.py, just more fields.
# ------------------------------------------------------------

# Core identity (optional, used only for evidence)
SUBJECT = r'''{{ $feature_extractor.message.subject }}'''
FROM_ADDR = r'''{{ $feature_extractor.message.from }}'''
FROM_DOMAIN = r'''{{ $feature_extractor.message.headers.from_domain }}'''

# Auth block (Feature_Extractor builds out["auth"] = {...})
SPF_RESULT  = r'''{{ $feature_extractor.message.auth.spf_result }}'''
DKIM_RESULT = r'''{{ $feature_extractor.message.auth.dkim_result }}'''
DMARC_RESULT= r'''{{ $feature_extractor.message.auth.dmarc_result }}'''

# URL block (Feature_Extractor builds out["urls"] = {...})
URL_ENTROPY_MAX  = r'''{{ $feature_extractor.message.urls.url_entropy_max }}'''
URL_ENTROPY_MEAN = r'''{{ $feature_extractor.message.urls.url_entropy_mean }}'''
URL_COUNT        = r'''{{ $feature_extractor.message.urls.url_count }}'''

# URL suspicious flags (Feature_Extractor mirrors suspicious_flags into urls.suspicious_flags)
ANY_SHORTENER        = r'''{{ $feature_extractor.message.urls.suspicious_flags.any_shortener }}'''
ANY_IP_HOST          = r'''{{ $feature_extractor.message.urls.suspicious_flags.any_ip_host }}'''
ANY_PUNYCODE         = r'''{{ $feature_extractor.message.urls.suspicious_flags.any_punycode }}'''
ANY_SUSPICIOUS_TLD   = r'''{{ $feature_extractor.message.urls.suspicious_flags.any_suspicious_tld }}'''
ANY_NON_ASCII_DOMAIN = r'''{{ $feature_extractor.message.urls.suspicious_flags.any_non_ascii_domain }}'''
ANY_AT_IN_URL        = r'''{{ $feature_extractor.message.urls.suspicious_flags.any_at_in_url }}'''

# Content signals
PHRASE_HIT_COUNT   = r'''{{ $feature_extractor.message.content.phrase_hit_count }}'''
HAS_HTML           = r'''{{ $feature_extractor.message.content.has_html }}'''
HAS_FORM           = r'''{{ $feature_extractor.message.content.has_form }}'''
HAS_PASSWORD_FIELD = r'''{{ $feature_extractor.message.content.has_password_field }}'''
SUBJECT_UPPER_RATIO= r'''{{ $feature_extractor.message.content.subject_upper_ratio }}'''
SUBJECT_EXCLAIMS   = r'''{{ $feature_extractor.message.content.subject_exclaim_count }}'''
BODY_EXCLAIMS      = r'''{{ $feature_extractor.message.content.body_exclaim_count }}'''
DIGIT_RATIO        = r'''{{ $feature_extractor.message.content.digit_ratio }}'''

# Header mismatch signals
REPLY_TO_MISMATCH     = r'''{{ $feature_extractor.message.headers.reply_to_mismatch }}'''
RETURN_PATH_MISMATCH  = r'''{{ $feature_extractor.message.headers.return_path_mismatch }}'''
MESSAGE_ID_PRESENT    = r'''{{ $feature_extractor.message.headers.message_id_present }}'''

# Attachments
ATTACHMENT_COUNT          = r'''{{ $feature_extractor.message.attachments.count }}'''
HAS_SUSPICIOUS_ATTACHMENT = r'''{{ $feature_extractor.message.attachments.has_suspicious_attachment }}'''

# ----------------------------
# Converters (very tolerant)
# ----------------------------

def _looks_unexpanded(s: str) -> bool:
    t = (s or "").strip()
    return t.startswith("{{") and t.endswith("}}")

def clean_str(s: str, default=""):
    if s is None:
        return default
    t = str(s).strip()
    if not t or t.lower() in ("null", "none", "undefined"):
        return default
    if _looks_unexpanded(t):
        return default
    return t

def to_float(s, default=0.0):
    try:
        t = clean_str(s, "")
        return float(t) if t != "" else float(default)
    except Exception:
        return float(default)

def to_int(s, default=0):
    try:
        t = clean_str(s, "")
        return int(float(t)) if t != "" else int(default)
    except Exception:
        return int(default)

def to_bool(s):
    t = clean_str(s, "").lower()
    if t in ("true", "1", "yes", "y", "on"):
        return True
    if t in ("false", "0", "no", "n", "off", ""):
        return False
    # If Liquid ever outputs Python booleans
    if t == "true":
        return True
    return False

# ----------------------------
# Pull + normalize fields
# ----------------------------

subject = clean_str(SUBJECT, "")
from_addr = clean_str(FROM_ADDR, "")
from_domain = clean_str(FROM_DOMAIN, "")

spf = clean_str(SPF_RESULT, "unknown").lower()
dkim = clean_str(DKIM_RESULT, "unknown").lower()
dmarc = clean_str(DMARC_RESULT, "unknown").lower()

url_entropy_max = to_float(URL_ENTROPY_MAX, 0.0)
url_entropy_mean = to_float(URL_ENTROPY_MEAN, 0.0)
url_count = to_int(URL_COUNT, 0)

any_shortener = to_bool(ANY_SHORTENER)
any_ip_host = to_bool(ANY_IP_HOST)
any_punycode = to_bool(ANY_PUNYCODE)
any_suspicious_tld = to_bool(ANY_SUSPICIOUS_TLD)
any_non_ascii_domain = to_bool(ANY_NON_ASCII_DOMAIN)
any_at_in_url = to_bool(ANY_AT_IN_URL)

phrase_hit_count = to_int(PHRASE_HIT_COUNT, 0)
has_html = to_bool(HAS_HTML)
has_form = to_bool(HAS_FORM)
has_password_field = to_bool(HAS_PASSWORD_FIELD)

subject_upper_ratio = to_float(SUBJECT_UPPER_RATIO, 0.0)
subject_exclaims = to_int(SUBJECT_EXCLAIMS, 0)
body_exclaims = to_int(BODY_EXCLAIMS, 0)
digit_ratio = to_float(DIGIT_RATIO, 0.0)

reply_to_mismatch = to_bool(REPLY_TO_MISMATCH)
return_path_mismatch = to_bool(RETURN_PATH_MISMATCH)
message_id_present = to_bool(MESSAGE_ID_PRESENT)

attachment_count = to_int(ATTACHMENT_COUNT, 0)
has_suspicious_attachment = to_bool(HAS_SUSPICIOUS_ATTACHMENT)

# If templates didn’t expand at all, bail with a clear error instead of nonsense scoring.
# (This avoids the “it ran but everything is default” confusion.)
must_have_any = [
    SPF_RESULT, URL_ENTROPY_MAX, PHRASE_HIT_COUNT, URL_COUNT,
]
if all(_looks_unexpanded(x.strip()) for x in must_have_any if (x or "").strip()):
    print(json.dumps({
        "success": False,
        "error": "Feature Extractor variables did not expand in Scoring Engine. Ensure the prior node is named 'feature_extractor' in this workflow.",
    }))
    raise SystemExit(0)

# ----------------------------
# Advanced scoring rules
# ----------------------------

risk = 0
triggers = []

def add(points, reason):
    global risk
    risk += int(points)
    triggers.append(reason)

# 1) Auth signals
if spf in ("fail", "softfail", "permerror"):
    add(35, f"SPF result: {spf}")
elif spf in ("temperror", "none"):
    add(10, f"SPF inconclusive: {spf}")

if dkim in ("fail", "permerror", "temperror"):
    add(20, f"DKIM result: {dkim}")
elif dkim == "none":
    add(6, "DKIM missing/none")

if dmarc == "fail":
    add(25, "DMARC failed")
elif dmarc == "none":
    add(6, "DMARC missing/none")

# 2) Header mismatch signals
if reply_to_mismatch:
    add(20, "Reply-To domain mismatch (common redirect-to-attacker pattern)")
if return_path_mismatch:
    add(15, "Return-Path mismatch (delivery path doesn’t align with From)")
if not message_id_present:
    add(6, "Missing Message-ID header (unusual for legit org mail)")

# 3) URL / link signals
if any_shortener:
    add(18, "URL shortener present (can hide destination)")
if any_ip_host:
    add(25, "URL host is a raw IP address (highly suspicious)")
if any_punycode or any_non_ascii_domain:
    add(20, "IDN/punycode or non-ASCII domain detected (lookalike risk)")
if any_suspicious_tld:
    add(12, "Suspicious TLD detected")
if any_at_in_url:
    add(12, "URL contains '@' (credential/confusion trick)")

# Entropy heuristics
if url_entropy_max >= 4.2:
    add(20, f"High URL path/query entropy (max={url_entropy_max})")
elif url_entropy_max >= 4.0:
    add(15, f"Elevated URL path/query entropy (max={url_entropy_max})")
elif url_entropy_mean >= 3.6:
    add(8, f"Moderately elevated avg URL entropy (mean={url_entropy_mean})")

# URL count heuristics
if url_count >= 8:
    add(10, f"Many URLs ({url_count})")
elif url_count >= 4:
    add(6, f"Multiple URLs ({url_count})")
elif url_count == 1 and any_shortener:
    add(6, "Single link + shortener combo (classic phish pattern)")

# 4) Content + phrasing
if phrase_hit_count >= 6:
    add(35, f"Very high phishy phrasing density ({phrase_hit_count} hits)")
elif phrase_hit_count >= 3:
    add(25, f"High phishy phrasing density ({phrase_hit_count} hits)")
elif phrase_hit_count > 0:
    add(10, f"Some risky phrasing present ({phrase_hit_count} hits)")

# HTML form/password field is a major indicator
if has_password_field:
    add(35, "HTML contains password field (credential-harvest indicator)")
elif has_form and has_html:
    add(22, "HTML contains a form (credential-harvest indicator)")
elif has_form:
    add(12, "Form detected")

# Subject heuristics (lightweight, avoid overfitting)
subj_l = (subject or "").lower()
if any(k in subj_l for k in ["action required", "verify", "password", "invoice", "security alert"]):
    add(8, "Subject contains urgency/account/security language")
if subject_upper_ratio >= 0.75:
    add(8, f"Subject is mostly uppercase (ratio={subject_upper_ratio})")
elif subject_upper_ratio >= 0.55:
    add(4, f"Subject has elevated uppercase ratio (ratio={subject_upper_ratio})")

if subject_exclaims >= 2:
    add(4, f"Multiple exclamation marks in subject ({subject_exclaims})")
if body_exclaims >= 4:
    add(3, f"Many exclamation marks in body ({body_exclaims})")
if digit_ratio >= 0.15:
    add(4, f"High digit ratio in body (ratio={digit_ratio})")

# 5) Attachments
if has_suspicious_attachment:
    add(40, "Suspicious attachment extension detected")
elif attachment_count > 0:
    add(8, f"Email has attachments ({attachment_count})")

# Cap the score
risk = max(0, min(100, risk))

# Verdict thresholds (tuned for your example: shortener + 'click here' should not be "Clean")
verdict = "Clean"
if risk >= 70:
    verdict = "Malicious"
elif risk >= 30:
    verdict = "Suspicious"

print(json.dumps({
    "success": True,
    "final_score": risk,
    "verdict": verdict,
    "triggers": triggers[:20],
    "evidence": {
        "subject": subject,
        "from": from_addr,
        "from_domain": from_domain,
        "auth": {"spf": spf, "dkim": dkim, "dmarc": dmarc},
        "urls": {
            "url_entropy_max": url_entropy_max,
            "url_entropy_mean": url_entropy_mean,
            "url_count": url_count,
            "flags": {
                "any_shortener": any_shortener,
                "any_ip_host": any_ip_host,
                "any_punycode": any_punycode,
                "any_suspicious_tld": any_suspicious_tld,
                "any_non_ascii_domain": any_non_ascii_domain,
                "any_at_in_url": any_at_in_url,
            }
        },
        "content": {
            "phrase_hit_count": phrase_hit_count,
            "has_html": has_html,
            "has_form": has_form,
            "has_password_field": has_password_field,
            "subject_upper_ratio": subject_upper_ratio,
            "subject_exclaim_count": subject_exclaims,
            "body_exclaim_count": body_exclaims,
            "digit_ratio": digit_ratio
        },
        "headers": {
            "reply_to_mismatch": reply_to_mismatch,
            "return_path_mismatch": return_path_mismatch,
            "message_id_present": message_id_present
        },
        "attachments": {
            "count": attachment_count,
            "has_suspicious_attachment": has_suspicious_attachment
        }
    }
}))
</textarea>
</div>
    </details>

    <p><strong>Save your Workflow</strong> (Floppy disk icon at the bottom).</p>

    <hr style="border: 0; border-top: 1px solid #eee; margin: 30px 0;">

    <h2 style="color: #0056b3;">Part 2: The Attack (Injection)</h2>
    <p>We will now use the Desktop Terminal to manually forward a phishing email to our new automation pipeline.</p>

    <h3>2.1 Save the Evidence</h3>
    <ol>
        <li>Inside the <strong>SOC Desktop</strong>, open <strong>Claws Mail</strong>.</li>
        <li>Right-click the "URGENT: 2FA Reset" email.</li>
        <li>Select <strong>Save as...</strong> and save it to the Desktop as <code>phish.eml</code>.</li>
    </ol>

    <h3>2.2 Prepare the Terminal</h3>
    <p>Open the Terminal inside the SOC Desktop. First, ensure we have the necessary tool:</p>
    <code style="background: #2d3b45; color: #fff; padding: 5px; display: block; margin-bottom: 10px;">sudo apt update && sudo apt install -y curl</code>

    <h3>2.3 Run the Injection</h3>
    <p>Copy and paste these commands one by one to ensure the data sends correctly. <br><strong>IMPORTANT:</strong> Paste your Webhook ID (from Step 1.1) into the first line.</p>

    <div style="background: #2d3b45; color: #fff; padding: 15px; border-radius: 4px; overflow-x: auto;">
        <code style="display: block; margin-bottom: 10px; color: #81a1c1;"># 1. Store your Webhook ID (Paste yours here!)</code>
        <code style="display: block; margin-bottom: 10px;">HOOK_ID="YOUR-UUID-GOES-HERE"</code>
        
        <code style="display: block; margin-bottom: 10px; color: #81a1c1;"># 2. Encode the email file into a variable</code>
        <code style="display: block; margin-bottom: 10px;">EMAIL_DATA=$(base64 -w0 ~/Desktop/phish.eml)</code>

        <code style="display: block; margin-bottom: 10px; color: #81a1c1;"># 3. Send the data securely (using -k to trust the certificate)</code>
        <code style="display: block;">curl -k -s -X POST "https://soc-shuffle-frontend/api/v1/hooks/$HOOK_ID" \
-H 'Content-Type: application/json' \
-d "{\"data\":{\"eml_b64\":\"$EMAIL_DATA\"}}"</code>
    </div>

    <p>If successful, you will see a message: <code>{"success": true, "execution_id": "..."}</code>.</p>

    <hr style="border: 0; border-top: 1px solid #eee; margin: 30px 0;">

    <h2 style="color: #0056b3;">Part 3: Viewing the Results</h2>
    <p>You sent the email to the automation engine. Now, let's see if it caught the phish.</p>

    <h3>3.1 Locate the Execution</h3>
    <ol>
        <li>Go back to your <strong>Shuffle Dashboard</strong>.</li>
        <li>Open your <strong>"ML Phishing Analyzer"</strong> workflow.</li>
        <li>Look at the <strong>Bottom Menu Bar</strong>. Click the icon that looks like a <strong>Person Running</strong> (the "Runs" button).</li>
        <li>Click the <strong>Top Item</strong> in the list (this is your latest attack).</li>
    </ol>

    <h3>3.2 Inspect the Verdict</h3>
    <ol>
        <li>You will see your nodes with green checkmarks.</li>
        <li>Click the <strong>Scoring_Engine</strong> node (the last one).</li>
        <li>A panel will slide out on the right. Click the <strong>"Output"</strong> or <strong>"Result"</strong> tab.</li>
        <li>You should see the final analysis:</li>
    </ol>

    <div style="background-color: #d4edda; color: #155724; padding: 15px; border: 1px solid #c3e6cb; border-radius: 5px;">
        <strong>✅ Successful Detection:</strong>
        <pre style="margin: 0; font-weight: bold;">
{
    "final_score": 70,
    "verdict": "Malicious",
    "triggers": [
        "High Entropy URL: http://login-secure-update-89sd7f.net...",
        "SPF Validation Failed"
    ]
}</pre>
    </div>

</div>
<script>
function copyCode(id){
  const el = document.getElementById(id);
  if(!el) return;
  el.focus();
  el.select();
  try{
    document.execCommand('copy');
  }catch(e){
    // ignore; user can still Ctrl+C
  }
}
</script>
